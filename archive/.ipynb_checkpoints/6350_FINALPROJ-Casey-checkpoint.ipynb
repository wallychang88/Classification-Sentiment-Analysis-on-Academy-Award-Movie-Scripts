{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d4b2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/caseykaufman/opt/anaconda3/envs/3350/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import TruncatedSVDfrom   \n",
    "from nltk.tokenize import word_tokenize\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5260aefe-2690-4658-a2f3-6e7c8488a401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "\n",
    "    result = chardet.detect(raw_data)\n",
    "    return result['encoding']\n",
    "\n",
    "def srt_to_text(srt_file_path):\n",
    "    encoding_attempts = ['utf-8', 'ISO-8859-1', 'utf-16', ]\n",
    "\n",
    "    for encoding in encoding_attempts:\n",
    "        try:\n",
    "            with open(srt_file_path, 'r', encoding=encoding) as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            text = \"\"\n",
    "            current_line = \"\"\n",
    "            is_time_line = True\n",
    "\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "\n",
    "                if not line:\n",
    "                    is_time_line = True\n",
    "                    continue\n",
    "\n",
    "                if is_time_line:\n",
    "                    is_time_line = False\n",
    "                    continue\n",
    "\n",
    "                current_line += line + \" \"\n",
    "\n",
    "                # If the line ends with a punctuation indicating the end of a sentence\n",
    "                if line.endswith(('.', '!', '?')):\n",
    "                    text += current_line + \"\\n\"\n",
    "                    current_line = \"\"\n",
    "\n",
    "            return text.strip()\n",
    "        except UnicodeDecodeError:\n",
    "            None\n",
    "\n",
    "    # If none of the encodings work\n",
    "    print(f\"Unable to decode file: {srt_file_path}\")\n",
    "    return None\n",
    "\n",
    "def process_srt_files_in_folder(folder_path):\n",
    "    result_dict = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".srt\"):\n",
    "            srt_file_path = os.path.join(folder_path, filename)\n",
    "            text_content = srt_to_text(srt_file_path)\n",
    "\n",
    "            if text_content is not None:\n",
    "                file_dict = {\"name\": filename, \"text\": text_content}\n",
    "                result_dict.append(file_dict)\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Example usage for a folder containing SRT files\n",
    "# wally = '/Users/wally/Library/CloudStorage/OneDrive-Personal/Documents/Cornell/1. Fourth Year/INFO 6350 - Text Mining History and Literature/INFO6350_Final_Project/srt_files'\n",
    "casey = '/Users/caseykaufman/Documents/GitHub/INFO6350_Final_Project/srt_files'\n",
    "\n",
    "folder_path = casey\n",
    "\n",
    "result_dictionary = process_srt_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e7947f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_subtitles_df = pd.DataFrame(result_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd84e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removal of timestamps\n",
    "movie_subtitles_df['text'] = movie_subtitles_df['text'].str.replace(r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}[\\s-]+', '\\n', regex=True)\n",
    "movie_subtitles_df['text'] = movie_subtitles_df['text'].str.replace(r'<font.*?>|<\\/font>', '', regex=True)\n",
    "movie_subtitles_df['text'] = movie_subtitles_df['text'].str.replace(r'\\bdownloaded.*?|subtitles downloaded.*?|http.*?|www.*?', '', regex=True, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6aba171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee1b940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years = []\n",
    "for name_index in range(len(movie_subtitles_df['name'])):\n",
    "    found_year = False\n",
    "    for letter_index in range(len(movie_subtitles_df['name'][name_index])):\n",
    "        if movie_subtitles_df['name'][name_index][letter_index:letter_index+2] == '19' and movie_subtitles_df['name'][name_index][letter_index:letter_index+4].isdigit() or movie_subtitles_df['name'][name_index][letter_index:letter_index+2] == '20' and movie_subtitles_df['name'][name_index][letter_index:letter_index+4].isdigit():\n",
    "            y = movie_subtitles_df['name'][name_index][letter_index:letter_index+4]\n",
    "            years.append(y)\n",
    "            found_year = True\n",
    "            break\n",
    "    if not found_year:\n",
    "        years.append('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514801c9-de1d-4ec0-a6ab-35e606e287c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_subtitles_df['years'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69fe9436-db15-413d-b85c-20d8f31a0793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunset Blvd. (1950)_english.srt</td>\n",
       "      <td>\\nYes, this is Sunset Boulevard, Los Angeles, ...</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diner.1982.720p.BluRay.x264-AMIABLE.srt</td>\n",
       "      <td>\\nA little bit softer now - Shout \\nA little b...</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road.To.Utopia.1945.1080p.BluRay.x264-[YTS.AM]...</td>\n",
       "      <td>\\nFor those of you who don't go to the movies,...</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tender Mercies (1983).srt</td>\n",
       "      <td>\\nHere, give me the bottle. \\n- Go to hell. \\n...</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghandi.1982.1080p.BluRay.x264.YIFY.srt</td>\n",
       "      <td>\\nThere are more than yesterday. \\n\\nHe will b...</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The.Sting.English-WWW.MY-SUBS.CO.srt</td>\n",
       "      <td>\\nLet's see what you got. \\n\\nI need more runn...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Designing.Woman.1957.720p.BluRay.x264-[YTS.AM]...</td>\n",
       "      <td>\\nMy name's Mike Hagen. \\n\\nI'm a sportswriter...</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Klute.English-WWW.MY-SUBS.CO.srt</td>\n",
       "      <td>\\nCan I do this? What do I do? \\nShall I do th...</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Tin Star (1957).srt</td>\n",
       "      <td>\\nJust getting the feel of these guns. \\n\\nWhe...</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In Which We Serve (1942) - Eng Sub.srt</td>\n",
       "      <td>\\nThis is the story of a ship \\n(Cheering) \\n(...</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                    Sunset Blvd. (1950)_english.srt   \n",
       "1            Diner.1982.720p.BluRay.x264-AMIABLE.srt   \n",
       "2  Road.To.Utopia.1945.1080p.BluRay.x264-[YTS.AM]...   \n",
       "3                          Tender Mercies (1983).srt   \n",
       "4             Ghandi.1982.1080p.BluRay.x264.YIFY.srt   \n",
       "5               The.Sting.English-WWW.MY-SUBS.CO.srt   \n",
       "6  Designing.Woman.1957.720p.BluRay.x264-[YTS.AM]...   \n",
       "7                   Klute.English-WWW.MY-SUBS.CO.srt   \n",
       "8                            The Tin Star (1957).srt   \n",
       "9             In Which We Serve (1942) - Eng Sub.srt   \n",
       "\n",
       "                                                text years  \n",
       "0  \\nYes, this is Sunset Boulevard, Los Angeles, ...  1950  \n",
       "1  \\nA little bit softer now - Shout \\nA little b...  1982  \n",
       "2  \\nFor those of you who don't go to the movies,...  1945  \n",
       "3  \\nHere, give me the bottle. \\n- Go to hell. \\n...  1983  \n",
       "4  \\nThere are more than yesterday. \\n\\nHe will b...  1982  \n",
       "5  \\nLet's see what you got. \\n\\nI need more runn...    na  \n",
       "6  \\nMy name's Mike Hagen. \\n\\nI'm a sportswriter...  1957  \n",
       "7  \\nCan I do this? What do I do? \\nShall I do th...    na  \n",
       "8  \\nJust getting the feel of these guns. \\n\\nWhe...  1957  \n",
       "9  \\nThis is the story of a ship \\n(Cheering) \\n(...  1942  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_subtitles_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00d84eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cleaning names\n",
    "pattern1= r'^([^\\d(]+)(?:\\.\\d{4}| \\(\\d{4}\\))?\\.?[^\\w]*'\n",
    "pattern2 = r'^[^a-zA-Z]*(.*?)\\.[a-zA-Z]{3}\\b'\n",
    "pattern3 = r'^[^a-zA-Z]*(.*?)\\.[a-zA-Z]{3}-'\n",
    "\n",
    "clean_names = []\n",
    "for file_name in movie_subtitles_df['name']:\n",
    "    match = re.match(pattern1, file_name) or re.match(pattern2, file_name) or re.match(pattern3, file_name)\n",
    "    if match:\n",
    "        extracted_name = match.group(1).replace('.', ' ')\n",
    "        clean_names.append(extracted_name)\n",
    "    else:\n",
    "        print(\"Name extraction pattern not found for:\", file_name)\n",
    "        \n",
    "new = [name.split('WWW')[0].strip() if 'WWW' in name else name for name in clean_names]\n",
    "clean_names = [x.replace('-','') for x in new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baff62b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_subtitles_df['Movie Name'] = clean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ceda15-18a7-4cdb-901a-38d887479eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>years</th>\n",
       "      <th>Movie Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunset Blvd. (1950)_english.srt</td>\n",
       "      <td>\\nYes, this is Sunset Boulevard, Los Angeles, ...</td>\n",
       "      <td>1950</td>\n",
       "      <td>Sunset Blvd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diner.1982.720p.BluRay.x264-AMIABLE.srt</td>\n",
       "      <td>\\nA little bit softer now - Shout \\nA little b...</td>\n",
       "      <td>1982</td>\n",
       "      <td>Diner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road.To.Utopia.1945.1080p.BluRay.x264-[YTS.AM]...</td>\n",
       "      <td>\\nFor those of you who don't go to the movies,...</td>\n",
       "      <td>1945</td>\n",
       "      <td>Road To Utopia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tender Mercies (1983).srt</td>\n",
       "      <td>\\nHere, give me the bottle. \\n- Go to hell. \\n...</td>\n",
       "      <td>1983</td>\n",
       "      <td>Tender Mercies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghandi.1982.1080p.BluRay.x264.YIFY.srt</td>\n",
       "      <td>\\nThere are more than yesterday. \\n\\nHe will b...</td>\n",
       "      <td>1982</td>\n",
       "      <td>Ghandi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                    Sunset Blvd. (1950)_english.srt   \n",
       "1            Diner.1982.720p.BluRay.x264-AMIABLE.srt   \n",
       "2  Road.To.Utopia.1945.1080p.BluRay.x264-[YTS.AM]...   \n",
       "3                          Tender Mercies (1983).srt   \n",
       "4             Ghandi.1982.1080p.BluRay.x264.YIFY.srt   \n",
       "\n",
       "                                                text years       Movie Name  \n",
       "0  \\nYes, this is Sunset Boulevard, Los Angeles, ...  1950    Sunset Blvd    \n",
       "1  \\nA little bit softer now - Shout \\nA little b...  1982           Diner   \n",
       "2  \\nFor those of you who don't go to the movies,...  1945  Road To Utopia   \n",
       "3  \\nHere, give me the bottle. \\n- Go to hell. \\n...  1983  Tender Mercies   \n",
       "4  \\nThere are more than yesterday. \\n\\nHe will b...  1982          Ghandi   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_subtitles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90400804-2424-4ccd-9fa8-f0ec0b26bdc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding win/loss\n",
    "excel = pd.read_csv('scripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb2902fb-7d32-4537-9c4c-11c470469686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#getting index values\n",
    "highest = []\n",
    "for films in clean_names: \n",
    "    similarity = []\n",
    "    indexes = []\n",
    "    for all_films in excel['Film']:\n",
    "        sim = fuzz.ratio(str(films), str(all_films))\n",
    "        similarity.append(sim)\n",
    "    highest.append(similarity.index(max(similarity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62463e9f-ddd9-4619-82b3-8d3af68cae3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_name_check = []\n",
    "win_loss = []\n",
    "for idx in highest:\n",
    "    value1 = excel.loc[idx,'Film']\n",
    "    value2 = excel.loc[idx,'Win']\n",
    "    movie_name_check.append(value1)\n",
    "    win_loss.append(value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba6edea5-03eb-4a94-84ff-ffcbe14290b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_subtitles_df['Similarity Calc Name'] = movie_name_check\n",
    "movie_subtitles_df['Win or Loss'] = win_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3df7ad1-17f2-4dd3-b008-f3c633df9829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>years</th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Similarity Calc Name</th>\n",
       "      <th>Win or Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunset Blvd. (1950)_english.srt</td>\n",
       "      <td>\\nYes, this is Sunset Boulevard, Los Angeles, ...</td>\n",
       "      <td>1950</td>\n",
       "      <td>Sunset Blvd</td>\n",
       "      <td>Sunset Boulevard</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diner.1982.720p.BluRay.x264-AMIABLE.srt</td>\n",
       "      <td>\\nA little bit softer now - Shout \\nA little b...</td>\n",
       "      <td>1982</td>\n",
       "      <td>Diner</td>\n",
       "      <td>Diner</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Road.To.Utopia.1945.1080p.BluRay.x264-[YTS.AM]...</td>\n",
       "      <td>\\nFor those of you who don't go to the movies,...</td>\n",
       "      <td>1945</td>\n",
       "      <td>Road To Utopia</td>\n",
       "      <td>Road to Utopia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tender Mercies (1983).srt</td>\n",
       "      <td>\\nHere, give me the bottle. \\n- Go to hell. \\n...</td>\n",
       "      <td>1983</td>\n",
       "      <td>Tender Mercies</td>\n",
       "      <td>Tender Mercies</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghandi.1982.1080p.BluRay.x264.YIFY.srt</td>\n",
       "      <td>\\nThere are more than yesterday. \\n\\nHe will b...</td>\n",
       "      <td>1982</td>\n",
       "      <td>Ghandi</td>\n",
       "      <td>Gandhi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                    Sunset Blvd. (1950)_english.srt   \n",
       "1            Diner.1982.720p.BluRay.x264-AMIABLE.srt   \n",
       "2  Road.To.Utopia.1945.1080p.BluRay.x264-[YTS.AM]...   \n",
       "3                          Tender Mercies (1983).srt   \n",
       "4             Ghandi.1982.1080p.BluRay.x264.YIFY.srt   \n",
       "\n",
       "                                                text years       Movie Name  \\\n",
       "0  \\nYes, this is Sunset Boulevard, Los Angeles, ...  1950    Sunset Blvd     \n",
       "1  \\nA little bit softer now - Shout \\nA little b...  1982           Diner    \n",
       "2  \\nFor those of you who don't go to the movies,...  1945  Road To Utopia    \n",
       "3  \\nHere, give me the bottle. \\n- Go to hell. \\n...  1983  Tender Mercies    \n",
       "4  \\nThere are more than yesterday. \\n\\nHe will b...  1982          Ghandi    \n",
       "\n",
       "  Similarity Calc Name  Win or Loss  \n",
       "0     Sunset Boulevard          1.0  \n",
       "1                Diner          0.0  \n",
       "2       Road to Utopia          0.0  \n",
       "3       Tender Mercies          1.0  \n",
       "4               Gandhi          1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_subtitles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb6c4c-dd72-4dee-9979-4e17f78a931f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df256547",
   "metadata": {},
   "source": [
    "## Create Chunks of Tokens out of the Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc625a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a topic model based on chunking with chunk size 200 tokens\n",
    "\n",
    "def generate_chunks(paragraphs, movie, year, chunk_size=200):\n",
    "    chunks = []\n",
    "    chunk_movie_name = []\n",
    "    chunk_year = []\n",
    "\n",
    "    for i in range(len(paragraphs)):\n",
    "        text = paragraphs.iloc[i]  # Extract the text from the Series\n",
    "        newsletter_type = movie.iloc[i]\n",
    "        date = year.iloc[i]\n",
    "\n",
    "        # Split the text into paragraphs using '\\n'\n",
    "        text_paragraphs = text.split('\\n')\n",
    "\n",
    "        current_chunk = []\n",
    "        current_chunk_movie_name = []\n",
    "\n",
    "        for paragraph in text_paragraphs:\n",
    "            # Check if the length of the paragraph exceeds the chunk size\n",
    "            if len(paragraph) > chunk_size:\n",
    "                chunks.append(paragraph)\n",
    "                chunk_movie_name.append(newsletter_type)\n",
    "                chunk_year.append(date)\n",
    "            else:\n",
    "                # If not, add the paragraph to the current chunk\n",
    "                current_chunk.append(paragraph)\n",
    "                current_chunk_movie_name.append(newsletter_type)\n",
    "\n",
    "                # Check if the current chunk size exceeds the specified limit\n",
    "                if len(' '.join(current_chunk)) > chunk_size:\n",
    "                    chunks.append(' '.join(current_chunk))\n",
    "                    chunk_year.extend([date])\n",
    "                    chunk_movie_name.append(newsletter_type)\n",
    "                    current_chunk = []\n",
    "                    current_chunk_movie_name = []\n",
    "\n",
    "        # Add any remaining paragraphs to the last chunk\n",
    "        if current_chunk:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            chunk_year.extend([date])\n",
    "            chunk_movie_name.append(newsletter_type)\n",
    "\n",
    "    return chunks, chunk_movie_name, chunk_year\n",
    "\n",
    "# Generate chunks\n",
    "text_chunks, chunk_movie_name, chunk_year = generate_chunks(movie_subtitles_df['text'], movie_subtitles_df['name'], movie_subtitles_df['years'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9f51e",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2be987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "vectorizer = CountVectorizer( # Token counts, not normalized (sklearn normalizes later)\n",
    "    input = 'content',\n",
    "    encoding = 'utf-8',\n",
    "    strip_accents = 'unicode',\n",
    "    #stop_words='english', # uncomment to remove fixed stops from input\n",
    "    lowercase = True,\n",
    "    min_df = 0.001, # Remember that we've chunked by paragraph\n",
    "    max_df = 0.25    # Ditto\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e38c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17b6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorized texts\n",
    "X_chunked = vectorizer.fit_transform(text_chunks)\n",
    "\n",
    "#X_topics_chunked = StandardScaler().fit_transform(lda.fit_transform(X_chunked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc0bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9542aa6",
   "metadata": {},
   "source": [
    "## KMeans Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec678c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=3, n_init='auto').fit_predict(X_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function\n",
    "def plot_compare(X, labels, title, alpha=0.2):\n",
    "    '''\n",
    "    Takes an array of object data, a list of cluster labels, a title string, and an optional alpha value.\n",
    "    Reduces dimensions to 2 if necessary and plots the clustering with and without coloring by label.\n",
    "    Returns nothing.\n",
    "    '''\n",
    "    if X.shape[1] > 2:\n",
    "        svd = TruncatedSVD(n_components=2)\n",
    "        X_2d = svd.fit_transform(X)\n",
    "    else:\n",
    "        X_2d = X\n",
    "\n",
    "    # initialize figsize in prompt\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # left subplot, alpha value in function cell\n",
    "    plt.subplot(121)\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], alpha=alpha)\n",
    "    plt.title(\"Dimension-Reduced Unclustered Data\")\n",
    "\n",
    "    # right subplot, same coordinate data and supplied cluster labels, alpha value in function cell\n",
    "    plt.subplot(122)\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, alpha=alpha)\n",
    "    plt.title(\"Data with Clustering\")\n",
    "\n",
    "    # Set the common title for the entire figure\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot resulting clustering\n",
    "plot_compare(X_chunked, y_pred, 'k-Means Clustering with 3 Groups on Vectorized Movie Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305fe42",
   "metadata": {},
   "source": [
    "# Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0efcb-d2c2-49a4-917c-d85c901c4afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460f625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(\n",
    "    n_components=50, # Number of topics to find\n",
    "    n_jobs=-1,       # Use all CPU cores\n",
    "    verbose=0,       # Print progress\n",
    "    max_iter=30,     # Might want more in production work\n",
    "    evaluate_every=0 # Set >=1 to test for convergence (slow, but can stop iteration)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c57f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words, hide_stops=False):\n",
    "    if hide_stops:\n",
    "        from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = f\"Topic {topic_idx: >2}: \"\n",
    "        top_words_idx = topic.argsort()\n",
    "        if not hide_stops:\n",
    "            top_words = [feature_names[i]\n",
    "                         for i in top_words_idx[:-n_top_words - 1:-1]]\n",
    "        else:\n",
    "            top_words = []\n",
    "            i = 1\n",
    "            while len(top_words) < n_top_words:\n",
    "                if feature_names[top_words_idx[-i]] not in ENGLISH_STOP_WORDS:\n",
    "                    top_words.append(feature_names[top_words_idx[-i]])\n",
    "                i += 1\n",
    "        message += \" \".join(top_words)    \n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbc8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_words(lda, vectorizer.get_feature_names_out(), n_top_words=10, hide_stops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1537e4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
